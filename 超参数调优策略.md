## 超参数调优经验分享与对比实验报告

机器学习中的神经网络模型常用来处理图像目标检测等问题，在模型训练时，超参数对训练效果影响很大。超参数包括学习率、批次大小、优化器类型等，它们的组合直接关系到模型的最终表现，所以超参数调优是模型调优的重要手段。

### 一、超参数类型

按照作用场景，超参数主要分三大类：模型结构类、训练过程类、正则化类。

1. 模型结构类

模型结构就像模型的“骨架”，不同模型结构对应的超参数不一样。比如神经网络里，能调整卷积核大小、隐藏层数量、每层神经元个数、滤波器数量、优化器类型等；树模型可以调最大深度、叶子节点最小样本数等；KNN和SVM也各有自己的超参数。

2. 训练过程类

训练过程中的超参数控制着模型训练的节奏和方向，常见的有批次大小、学习率、迭代次数、优化器类型及相关参数。这些参数构成了神经网络模型训练的基础框架，在其他条件不变时，优化这些参数能让模型找到当前情况下的最优解。

3. 正则化类

当模型结构确定，训练过程的超参数也优化完后，还能通过正则化超参数进一步调优，比如L1/L2正则化系数、权重衰减系数、dropout率、早停阈值等。它们的主要作用是防止模型过拟合，让模型在新数据上有更好的表现。

### 二、超参数调优策略

不同类型的超参数，调优策略也不同。

1. 模型结构类

现在基于神经网络的各种变体模型很热门，不少初学者喜欢用它们来处理各种训练任务。但实际上，选模型不能只看复杂程度，得结合现有资源、预期目标、成本等多方面因素。比如用iris数据集预测花色这种简单任务，选KNN、SVM这类简单模型就行，如果用神经网络，反而像“杀鸡用牛刀”，还容易过拟合。所以，选模型的核心是“适配”。

对于不同模型，超参数调优有讲究。尤其是现在很多模型被封装成可调用的API，黑盒部分越来越多，我们容易忽略超参数在模型中的具体作用，调优时就没了方向。其实要找对调优方向，得先明白对应模型里超参数的职责。比如神经网络的卷积核大小，它代表对特征图的“局部感知范围”，也就是模型每次“看”的格子数量，直接决定了单次卷积能捕捉到的空间细节。卷积核的参数数量是“核尺寸²×输入通道数×输出通道数”，所以卷积核越大，模型越复杂，拟合能力越强，但如果处理的是小数据集，过大的卷积核容易导致过拟合。因此选卷积核时，要考虑数据量大小和任务对细节的要求——数据少、任务不复杂，选小卷积核更稳妥；数据充足、需要捕捉复杂特征，再考虑用大卷积核或多种尺寸组合。

再比如隐藏层数量，层数太少，模型可能学不到复杂规律，出现欠拟合；层数太多，不仅训练慢，还可能记住噪声，导致过拟合。这就需要根据数据的复杂度来试：简单数据用3-5层可能就够，复杂的图像或文本数据，可能需要更多层，但要配合正则化手段。

2. 训练过程类

训练过程的超参数调优，关键是把握“训练节奏”。

批次大小影响训练效率和模型稳定性。批次太小，每次计算的梯度波动大，训练不稳定，而且频繁更新参数会增加计算成本；批次太大，虽然梯度更稳定，但内存消耗大，模型可能陷入局部最优。一般来说，小数据集可以用全量数据（批次等于样本数），中等数据集选32、64、128这类常见值，大数据集可能需要更大批次，但要注意配合学习率调整。

学习率是很关键的参数，它决定参数更新的幅度。学习率太大，模型可能跳过最优解，导致训练不稳定；太小则训练速度慢，容易陷入局部最优。调优时可以先从较大的学习率（0.1）开始，观察损失值变化：如果损失快速上升，说明学习率太大，得减小；如果损失下降很慢，就适当增大。也可以用学习率衰减策略，训练初期用较大学习率快速逼近最优解，后期减小学习率精细调整。

迭代次数（epoch）要足够让模型收敛，但也不能太多。太少的话，模型没学透，欠拟合；太多则可能过拟合，还浪费时间。可以观察验证集的损失变化，当损失不再下降甚至开始上升时，就可以停止训练了。

优化器类型也很重要。SGD（随机梯度下降）简单直观，但收敛慢，容易震荡；Adam结合了动量和自适应学习率，收敛快，稳定性好，适合很多场景；RMSprop在处理非平稳目标时表现不错。实际调优中，可以先试Adam，效果不好再换其他优化器，同时调整它们的参数（Adam的β1、β2）。

3. 正则化类

正则化类超参数的核心作用是“平衡拟合能力和泛化能力”。

L1正则化会让部分参数变为0，实现特征选择，适合处理高维稀疏数据，调优时可以从较小的系数（0.001）开始，逐渐增大，直到验证集性能提升。L2正则化让参数值整体变小，防止过拟合，应用更广泛，系数选择思路和L1类似，但通常比L1的最优值大一些。

权重衰减和L2正则化类似，很多框架里两者甚至等价，调优时可以和L2正则化结合起来看，避免重复调整。

Dropout率控制训练时随机“丢弃”的神经元比例，通过减少神经元之间的依赖来防止过拟合。率太小，正则化效果弱；太大，模型学习能力会下降。一般在0.2-0.5之间尝试，输入层可以用小一点的率，隐藏层用0.5左右。

早停阈值是根据验证集性能来决定何时停止训练。当验证集损失连续一定轮次没有下降时，就停止训练，避免过拟合。这个阈值不能太小，否则可能提前停止导致欠拟合；也不能太大，会浪费计算资源。

总的来说，超参数调优没有固定公式，需要结合具体任务、数据特点和模型类型，通过多次实验找到合适的组合。调优时可以先固定其他参数，每次只调整一个超参数，观察其对模型的影响，再逐步扩展到多参数组合，同时要始终以验证集性能作为判断标准。


### 三、以手写数字识别为例验证策略正确性

#### 1. 数据集说明

选用MNIST手写数字数据集作为验证基准，该数据集包含70000张分辨率为28×28的单通道黑白数字图像，涵盖0-9共10个数字类别，数据分布均匀、标注准确，是机器学习领域验证分类模型性能的经典数据集。为贴合“不同数据量对超参数调优影响”的验证目标，对数据集做两层拆分：
- 全量数据集：按经典划分方式分为60000个训练样本 + 10000个测试样本；
- 小数据集：随机抽取2000个训练样本 + 1000个测试样本（确保每个数字类别按比例抽取，避免类别失衡）。

#### 2. 验证策略设计

本次验证核心目标是：验证前文超参数调优策略在实际任务中的有效性，明确“不同数据量、不同模型类型、不同超参数类别”对最终性能的影响。整体遵循**控制变量法**，确保单一变量变化，其余条件固定，实验结果可对比、可复现。

##### （1）对照组与实验组设定
| 组别           | 数据集规模    | 模型类型    | 超参数调整范围                                               | 核心验证目标                         |
| -------------- | ------------- | ----------- | ------------------------------------------------------------ | ------------------------------------ |
| 基准对照组     | 全量/小数据集 | 最简CNN/KNN | 采用默认超参数（无调优）                                     | 确定基线性能，衡量调优收益           |
| 模型结构调优组 | 全量/小数据集 | 最简CNN     | 卷积核大小（3×3/5×5）、隐藏层数量（1/2/3层）                 | 验证结构类超参数适配性策略           |
| 训练过程调优组 | 全量/小数据集 | 最简CNN     | 批次大小（16/32/64）、学习率（0.001/0.01/0.1）、迭代次数（50/100/150） | 验证训练节奏类超参数调优策略         |
| 正则化调优组   | 全量/小数据集 | 调优后CNN   | Dropout率、L2正则化系数、早停阈值                            | 验证正则化平衡泛化能力的策略         |
| 模型对比组     | 全量/小数据集 | KNN         | 邻居数k（3/5/7）                                             | 验证“简单任务适配简单模型”的核心结论 |

##### （2）核心实验细节（确保严密性）
- 最简CNN模型结构（固定基准）：
  输入层（28×28×1）→ 卷积层（默认3×3卷积核，32个滤波器，ReLU激活）→ 池化层（2×2最大池化）→ 全连接层（128个神经元）→ 输出层（10个神经元，Softmax激活）；仅在“模型结构调优组”中调整卷积核大小和隐藏层数量。
- KNN模型（固定基准）：
  采用无监督预处理（归一化至[0,1]），默认k=5、欧氏距离，仅在“模型对比组”中调整k值和距离度量方式。
- 训练固定条件：
  优化器统一选用Adam（β1=0.9，β2=0.999），损失函数为交叉熵损失，训练环境（硬件、框架版本）一致，每组实验重复3次取平均值，避免随机种子导致的结果波动。
- 评价指标：
  核心指标为测试集准确率（反映整体分类效果），辅助指标包括训练耗时（反映效率）、过拟合程度（训练集准确率 - 测试集准确率，反映泛化能力）。

#### 3. 实验结果与验证结论

##### （1）实验总结

1. **模型性能对比**
    - 在全量数据集上，CNN模型整体整体表现优于KNN模型。基准对照组中，最简CNN的测试集准确率为98.53%，而KNN为96.88%；经过调优后，CNN的测试集准确率最高可达99.33%，远高于调整K值后KNN的43.75%。
    - 在小数据集上，CNN模型的测试集准确率也高于KNN模型，但过拟合程度相对较高。
2. **超参数影响**
    - **模型结构**：对于CNN，将卷积核从3×3调整为5×5后，在全量数据集上测试集准确率从98.53%提升至98.64%，小数据集上从93.20%提升至94.70%；增加隐藏层数量对性能影响不显著。
    - **训练过程**：增大批次大小和调整学习率对CNN性能有一定影响，其中学习率增大到0.01时，全量数据集测试集准确率下降至97.54%。
    - **正则化**：引入Dropout率为0.5的正则化后，CNN在全量数据集上测试集准确率提升至99.33%，小数据集上提升至98.30%，有效改善了性能。
3. **数据集影响**：相同模型在全量数据集上的过拟合程度明显低于小数据集，说明增加数据量可有效缓解过拟合。
4. **稳定性与效率**：KNN模型在两种数据集上均表现出“极不稳定”的特点；从训练耗时看，KNN耗时远低于CNN，但性能较差，CNN中调整模型结构和训练过程后耗时有所变化，整体在可接受范围内。


### 核心验证总结
1. **模型有效性验证**：CNN模型在图像分类任务中有效性显著高于KNN模型，尤其在全量数据集上优势明显，验证了CNN更适合处理此类数据。
2. **超参数调优有效性验证**
    - 模型结构调优对提升CNN性能有积极作用，验证了合理设计网络结构的重要性。
    - 正则化调优能有效提升CNN在不同规模数据集上的性能，验证了正则化对改善模型泛化能力的有效性。
    - 训练过程超参数设置不当会导致性能下降，验证了选择合适训练参数的必要性。
3. **数据集规模影响验证**：全量数据集能显著降低模型过拟合程度并提升性能，验证了充足的数据量是模型取得良好效果的重要基础。



# 附录 超参数调优实验训练信息记录表

| 实验编号 | 组别              | 数据集类型                | 模型类型  | 模型结构超参数                          | 训练过程超参数                                               | 正则化超参数                                   | 训练环境（硬件/框架） | 重复次数 | 训练耗时（min） | 训练集准确率（%） | 测试集准确率（%） | 过拟合程度（训练-测试）（%） | 备注（问题/优化点） |
| -------- | ----------------- | ------------------------- | --------- | --------------------------------------- | ------------------------------------------------------------ | ---------------------------------------------- | --------------------- | -------- | --------------- | ----------------- | ----------------- | ---------------------------- | ------------------- |
| 1        | 基准对照组        | 全量（60k训练+10k测试）   | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             | cpu                   | 1/2/3    | 462.72秒        | 99.89%            | 98.53%            | 1.36%                        |                     |
| 2        | 基准对照组        | 全量（60k训练+10k测试）   | KNN       | 邻居数k：5，距离度量：欧氏距离          | 无（KNN无训练过程超参数）                                    | 无                                             |                       | 1/2/3    | 32.67秒         | 98.19%            | 96.88%            | 1.31%                        | 极不稳定            |
| 3        | 基准对照组        | 小数据集（2k训练+1k测试） | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 10.11秒         | 100.00%           | 93.20%            | 7.10%                        |                     |
| 4        | 基准对照组        | 小数据集（2k训练+1k测试） | KNN       | 邻居数k：5，距离度量：欧氏距离          | 无（KNN无训练过程超参数）                                    | 无                                             |                       | 1/2/3    | 1.07秒          | 93.45%            | 87.30%            | 6.15%                        | 极不稳定            |
| 5        | 模型结构调优组    | 全量（60k训练+10k测试）   | 最简CNN   | 卷积核：5×5，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 436.27秒        | 100.00%           | 98.64%            | 1.15%                        | 调整卷积核大小      |
| 6        | 模型结构调优组    | 小数据集（2k训练+1k测试） | 最简CNN   | 卷积核：5×5，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 10.52秒         | 100.00%           | 94.70%            | 5.30%                        | 调整卷积核大小      |
| 7        | 模型结构调优组    | 全量（60k训练+10k测试）   | 最简CNN   | 卷积核：3×3，隐藏层：2层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 408.91秒        | 99.87%            | 98.56%            | 1.31%                        | 调整隐藏层数量      |
| 8        | 模型结构调优组    | 小数据集（2k训练+1k测试） | 最简CNN   | 卷积核：3×3，隐藏层：2层，神经元：128个 | 批次大小：32，学习率：0.001，迭代次数：10，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 10.25秒         | 100.00%           | 93.80%            | 6.20%                        | 调整隐藏层数量      |
| 9        | 训练过程调优组    | 全量（60k训练+10k测试）   | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：1000，学习率：0.001，迭代次数：100，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 387.22秒        | 99.74%            | 98.39%            | 1.35%                        | 调整批次大小        |
| 10       | 训练过程调优组    | 小数据集（2k训练+1k测试） | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：16，学习率：0.001，迭代次数：100，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 9.84秒          | 100.00%           | 93.50%            | 6.50%                        | 调整批次大小        |
| 11       | 训练过程调优组    | 全量（60k训练+10k测试）   | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.01，迭代次数：100，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 423.61秒        | 99.21%            | 97.54%            | 1.67%                        | 调整学习率          |
| 12       | 训练过程调优组    | 小数据集（2k训练+1k测试） | 最简CNN   | 卷积核：3×3，隐藏层：1层，神经元：128个 | 批次大小：32，学习率：0.01，迭代次数：100，优化器：Adam（β1=0.9,β2=0.999） | 无                                             |                       | 1/2/3    | 9.85秒          | 99.35%            | 89.20%            | 10.15%                       | 调整学习率          |
| 13       | 正则化调优组      | 全量（60k训练+10k测试）   | 调优后CNN | 最优结构超参数（如5×5卷积核+2层隐藏层） | 最优训练超参数（如批次64+学习率0.001+迭代100）               | Dropout率：0.5，L2正则化系数：0，早停阈值：3无 |                       | 1/2/3    |                 |                   | 99.33%            |                              | 调整Dropout率       |
| 14       | 正则化调优组      | 小数据集（2k训练+1k测试） | 调优后CNN | 最优结构超参数（如3×3卷积核+1层隐藏层） | 最优训练超参数（如批次16+学习率0.01+迭代50）                 | Dropout率：0.5，L2正则化系数：0，早停阈值：3无 |                       | 1/2/3    |                 |                   | 98.30%            |                              | 调整Dropout率       |
| 15       | 模型对比组（KNN） | 全量（60k训练+10k测试）   | KNN       | 邻居数k：3，距离度量：欧氏距离          | 无（KNN无训练过程超参数）                                    | 无                                             |                       | 1/2/3    | 0.18秒          | 75.00%            | 43.75%            | 31.25%                       | 调整K值             |
| 16       | 模型对比组（KNN） | 小数据集（2k训练+1k测试） | KNN       | 邻居数k：3，距离度量：欧氏距离          | 无（KNN无训练过程超参数）                                    | 无                                             |                       | 1/2/3    | 0.19秒          | 37.50%            | 68.75%            | -31.25%                      | 调整K值             |
